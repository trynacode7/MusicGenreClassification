{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Music Genre Classification Analysis\n",
        "\n",
        "This notebook provides comprehensive analysis and visualization of the music genre classification results using GTZAN dataset.\n",
        "\n",
        "## Overview\n",
        "- **Dataset**: GTZAN Music Genre Classification\n",
        "- **Models**: Random Forest, SVM, CNN\n",
        "- **Features**: 30-second audio features + Spectrogram images\n",
        "- **Genres**: 10 music genres (blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, rock)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model Results and Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load trained models and preprocessing artifacts\n",
        "models_dir = Path(\"../models\")\n",
        "results_dir = Path(\"../results\")\n",
        "\n",
        "# Load models\n",
        "try:\n",
        "    random_forest = joblib.load(models_dir / \"random_forest_model.pkl\")\n",
        "    svm = joblib.load(models_dir / \"svm_model.pkl\")\n",
        "    scaler = joblib.load(models_dir / \"scaler.pkl\")\n",
        "    label_encoder = joblib.load(models_dir / \"label_encoder.pkl\")\n",
        "    print(\"‚úì Models loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")\n",
        "\n",
        "# Load test data\n",
        "try:\n",
        "    X_test = joblib.load(models_dir / \"X_test.pkl\")\n",
        "    y_test = joblib.load(models_dir / \"y_test.pkl\")\n",
        "    print(f\"‚úì Test data loaded: {X_test.shape[0]} samples, {X_test.shape[1]} features\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading test data: {e}\")\n",
        "\n",
        "# Create results directory if it doesn't exist\n",
        "results_dir.mkdir(exist_ok=True)\n",
        "print(f\"‚úì Results directory: {results_dir.absolute()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Performance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test data\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Get predictions from both models\n",
        "rf_predictions = random_forest.predict(X_test)\n",
        "svm_predictions = svm.predict(X_test)\n",
        "\n",
        "# Calculate accuracies\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
        "\n",
        "# Get genre names\n",
        "genre_names = label_encoder.classes_\n",
        "print(f\"\\nGenres: {list(genre_names)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Confusion Matrices Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrices\n",
        "rf_cm = confusion_matrix(y_test, rf_predictions)\n",
        "svm_cm = confusion_matrix(y_test, svm_predictions)\n",
        "\n",
        "# Create subplot for confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Random Forest Confusion Matrix\n",
        "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=genre_names, yticklabels=genre_names,\n",
        "            ax=axes[0], cbar_kws={'shrink': 0.8})\n",
        "axes[0].set_title('Random Forest Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted Genre', fontsize=12)\n",
        "axes[0].set_ylabel('True Genre', fontsize=12)\n",
        "\n",
        "# SVM Confusion Matrix\n",
        "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Oranges', \n",
        "            xticklabels=genre_names, yticklabels=genre_names,\n",
        "            ax=axes[1], cbar_kws={'shrink': 0.8})\n",
        "axes[1].set_title('SVM Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted Genre', fontsize=12)\n",
        "axes[1].set_ylabel('True Genre', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_dir / 'confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úì Confusion matrices saved to results/confusion_matrices.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Accuracy Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create accuracy comparison plot\n",
        "models = ['Random Forest', 'SVM']\n",
        "accuracies = [rf_accuracy, svm_accuracy]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(models, accuracies, color=['#3498db', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "plt.title('Model Accuracy Comparison', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Model', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add horizontal line at 0.1 (random chance for 10 classes)\n",
        "plt.axhline(y=0.1, color='red', linestyle='--', alpha=0.7, label='Random Chance (10%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_dir / 'model_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úì Model accuracy comparison saved to results/model_accuracy_comparison.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Spectrogram Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display sample spectrograms\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Path to spectrogram images\n",
        "images_dir = Path(\"../Data/images_original\")\n",
        "\n",
        "if images_dir.exists():\n",
        "    # Create a grid of sample spectrograms\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, genre in enumerate(genre_names):\n",
        "        genre_dir = images_dir / genre\n",
        "        if genre_dir.exists():\n",
        "            # Get a random image from this genre\n",
        "            image_files = list(genre_dir.glob(\"*.png\"))\n",
        "            if image_files:\n",
        "                random_image = random.choice(image_files)\n",
        "                \n",
        "                # Load and display image\n",
        "                img = Image.open(random_image)\n",
        "                axes[i].imshow(img, cmap='viridis')\n",
        "                axes[i].set_title(f'{genre.title()}\\n{random_image.name}', fontsize=10, fontweight='bold')\n",
        "                axes[i].axis('off')\n",
        "            else:\n",
        "                axes[i].text(0.5, 0.5, f'No images\\nfor {genre}', ha='center', va='center', \n",
        "                           transform=axes[i].transAxes, fontsize=10)\n",
        "                axes[i].axis('off')\n",
        "        else:\n",
        "            axes[i].text(0.5, 0.5, f'No directory\\nfor {genre}', ha='center', va='center', \n",
        "                       transform=axes[i].transAxes, fontsize=10)\n",
        "            axes[i].axis('off')\n",
        "    \n",
        "    plt.suptitle('Sample Spectrograms by Genre', fontsize=16, fontweight='bold', y=0.95)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(results_dir / 'sample_spectrograms.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úì Sample spectrograms saved to results/sample_spectrograms.png\")\n",
        "else:\n",
        "    print(\"‚ö† Spectrogram images directory not found: ../Data/images_original\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Performance Summary Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive performance summary\n",
        "rf_report = classification_report(y_test, rf_predictions, target_names=genre_names, output_dict=True)\n",
        "svm_report = classification_report(y_test, svm_predictions, target_names=genre_names, output_dict=True)\n",
        "\n",
        "summary_data = {\n",
        "    'Model': ['Random Forest', 'SVM'],\n",
        "    'Accuracy': [rf_accuracy, svm_accuracy],\n",
        "    'Macro F1-Score': [rf_report['macro avg']['f1-score'], svm_report['macro avg']['f1-score']],\n",
        "    'Weighted F1-Score': [rf_report['weighted avg']['f1-score'], svm_report['weighted avg']['f1-score']]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "# Display summary table\n",
        "print(\"=\"*60)\n",
        "print(\"MUSIC GENRE CLASSIFICATION PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nDataset: GTZAN Music Genre Classification\")\n",
        "print(f\"Total Test Samples: {len(y_test)}\")\n",
        "print(f\"Number of Genres: {len(genre_names)}\")\n",
        "print(f\"Feature Dimensions: {X_test.shape[1]}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"-\"*60)\n",
        "print(summary_df.to_string(index=False, float_format='%.4f'))\n",
        "\n",
        "# Save summary to CSV\n",
        "summary_df.to_csv(results_dir / 'model_performance_summary.csv', index=False)\n",
        "print(f\"\\n‚úì Performance summary saved to results/model_performance_summary.csv\")\n",
        "\n",
        "# Best performing model\n",
        "best_model = 'Random Forest' if rf_accuracy > svm_accuracy else 'SVM'\n",
        "best_accuracy = max(rf_accuracy, svm_accuracy)\n",
        "print(f\"\\nüèÜ Best Performing Model: {best_model} (Accuracy: {best_accuracy:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
